{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":6877145,"sourceType":"datasetVersion","datasetId":3951583},{"sourceId":7218204,"sourceType":"datasetVersion","datasetId":4177593}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-17T11:27:06.055637Z","iopub.execute_input":"2023-12-17T11:27:06.055985Z","iopub.status.idle":"2023-12-17T11:27:06.059935Z","shell.execute_reply.started":"2023-12-17T11:27:06.055952Z","shell.execute_reply":"2023-12-17T11:27:06.059095Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# Loading the dataset for cleaning","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/original-dataset/ar41_for_ulb.csv', delimiter=';')","metadata":{"execution":{"iopub.status.busy":"2023-12-17T11:27:06.755660Z","iopub.execute_input":"2023-12-17T11:27:06.756124Z","iopub.status.idle":"2023-12-17T11:27:37.824083Z","shell.execute_reply.started":"2023-12-17T11:27:06.756080Z","shell.execute_reply":"2023-12-17T11:27:37.823374Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"## Null Value Analysis\nWe observed that the columns `RS_E_InAirTemp_PC2`, `RS_E_OilPress_PC2`, `RS_E_RPM_PC2`, `RS_E_WatTemp_PC2`, and `RS_T_OilTemp_PC2` each have 12,726 missing values. Given that the total dataset comprises 17.6 million rows, the proportion of missing values is relatively small. Therefore, we decided to remove these rows for a cleaner and more consistent dataset.","metadata":{}},{"cell_type":"code","source":"null_values = data.isnull().sum()\nnull_values","metadata":{"execution":{"iopub.status.busy":"2023-12-17T11:28:52.609274Z","iopub.execute_input":"2023-12-17T11:28:52.609603Z","iopub.status.idle":"2023-12-17T11:28:53.707417Z","shell.execute_reply.started":"2023-12-17T11:28:52.609578Z","shell.execute_reply":"2023-12-17T11:28:53.706687Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"Unnamed: 0                0\nmapped_veh_id             0\ntimestamps_UTC            0\nlat                       0\nlon                       0\nRS_E_InAirTemp_PC1        0\nRS_E_InAirTemp_PC2    12726\nRS_E_OilPress_PC1         0\nRS_E_OilPress_PC2     12726\nRS_E_RPM_PC1              0\nRS_E_RPM_PC2          12726\nRS_E_WatTemp_PC1          0\nRS_E_WatTemp_PC2      12726\nRS_T_OilTemp_PC1          0\nRS_T_OilTemp_PC2      12726\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"data.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T11:28:55.982776Z","iopub.execute_input":"2023-12-17T11:28:55.983139Z","iopub.status.idle":"2023-12-17T11:28:58.516642Z","shell.execute_reply.started":"2023-12-17T11:28:55.983099Z","shell.execute_reply":"2023-12-17T11:28:58.515956Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# Checking Number of duplicate rows\nThe dataset doesn't contain any duplicate rows","metadata":{}},{"cell_type":"code","source":"duplicates = data.duplicated()\nnum_duplicates = duplicates.sum()\nprint(f\"Number of duplicate rows: {num_duplicates}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-17T11:43:08.750314Z","iopub.execute_input":"2023-12-17T11:43:08.750656Z","iopub.status.idle":"2023-12-17T11:43:25.607415Z","shell.execute_reply.started":"2023-12-17T11:43:08.750626Z","shell.execute_reply":"2023-12-17T11:43:25.606633Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Number of duplicate rows: 0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Cleaning the Time Interval\n\nIn our data cleaning process, we focus on ensuring that the data falls within the specified time range of the project. To achieve this, we implement the following steps:\n\n1. **Timestamp Conversion**: The `timestamps_UTC` column is converted to a datetime format. \n\n2. **Defining the Time Range**: We define the time range of our project to be from January 1, 2023, to September 30, 2023. This period marks the temporal extent of our analysis.\n   - `start_date`: January 1, 2023\n   - `end_date`: September 30, 2023\n\n3. **Filtering Data**: Using the defined time range, we filter the dataset to identify and count any rows with timestamps that fall outside this specified interval. This step ensures that our analysis is confined to the relevant time period.","metadata":{}},{"cell_type":"code","source":"data['timestamps_UTC'] = pd.to_datetime(data['timestamps_UTC'])\n\nstart_date = '2023-01-01'\nend_date = '2023-09-30'\n\noutside_interval = data[(data['timestamps_UTC'] < pd.to_datetime(start_date)) | \n                        (data['timestamps_UTC'] > pd.to_datetime(end_date))]\n\nnum_rows_outside_interval = outside_interval.shape[0]\n\nprint(f\"Number of rows outside the given time interval: {num_rows_outside_interval}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-17T11:33:16.600425Z","iopub.execute_input":"2023-12-17T11:33:16.600729Z","iopub.status.idle":"2023-12-17T11:33:16.788042Z","shell.execute_reply.started":"2023-12-17T11:33:16.600703Z","shell.execute_reply":"2023-12-17T11:33:16.787331Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Number of rows outside the given time interval: 34\n","output_type":"stream"}]},{"cell_type":"code","source":"filtered_data = data[(data['timestamps_UTC'].dt.year == 2023) & (data['timestamps_UTC'].dt.month <= 9)]","metadata":{"execution":{"iopub.status.busy":"2023-12-17T11:33:17.672300Z","iopub.execute_input":"2023-12-17T11:33:17.672677Z","iopub.status.idle":"2023-12-17T11:33:19.520179Z","shell.execute_reply.started":"2023-12-17T11:33:17.672650Z","shell.execute_reply":"2023-12-17T11:33:19.519459Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"## Geospatial Data Filtering\n\nIn this step of our data cleaning process, we aim to remove specific geospatial data points that fall outside the geographical boundaries of Belgium.\n\n### Identified Coordinates for Removal\nWe have identified a list of latitude and longitude pairs that are outside the scope of our project by analyzing with PostGIS.","metadata":{}},{"cell_type":"code","source":"coordinates_to_remove = [\n    (52.8570588, 4.4855411),\n    (50.330024, 0.1750491),\n    (50.3979063, 0.2067928),\n    (49.3835907, 3.7002351),\n    (49.7800844, 3.7347805)\n]\n\nfor lat, lon in coordinates_to_remove:\n    filtered_data = filtered_data[~((filtered_data['lat'] == lat) & (filtered_data['lon'] == lon))]","metadata":{"execution":{"iopub.status.busy":"2023-12-17T11:34:17.356832Z","iopub.execute_input":"2023-12-17T11:34:17.357163Z","iopub.status.idle":"2023-12-17T11:34:23.061516Z","shell.execute_reply.started":"2023-12-17T11:34:17.357136Z","shell.execute_reply":"2023-12-17T11:34:23.060702Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"filtered_data.to_csv(\"/kaggle/working/cleaned_data.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-17T11:35:07.639940Z","iopub.execute_input":"2023-12-17T11:35:07.640264Z","iopub.status.idle":"2023-12-17T11:38:18.523502Z","shell.execute_reply.started":"2023-12-17T11:35:07.640237Z","shell.execute_reply":"2023-12-17T11:38:18.522422Z"},"trusted":true},"execution_count":48,"outputs":[]}]}